{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PartA_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPAKDeCjWLl3JdcDCUrlSC/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"GHGcdAlIwn1l","executionInfo":{"status":"error","timestamp":1619883144013,"user_tz":-60,"elapsed":16814,"user":{"displayName":"Shane Quinn","photoUrl":"","userId":"04299873785165069898"}},"outputId":"81d2c924-7604-48a2-bd23-a5943e77475c"},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Name: Shane Quinn\n","Student Number: R00144107\n","Email: shane.quinn1@mycit.ie\n","Course: MSc Artificial Intelligence\n","Module: Deep Learning\n","Date: 01/05/2021\n","\"\"\"\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n","# !unzip \"/content/gdrive/My Drive/datasets/earth_data.zip\" -d \"./\"\n","\n","# !ls\n","\n","import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","from tensorflow.python.client import device_lib\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.models import load_model\n","from sklearn.metrics import accuracy_score\n","import functools\n","import time\n","import os\n","\n","\n","def exec_time(func):\n","    \"\"\"\n","    Generic Execution time recorder, pass in function. Records execution time using decorators\n","    Have used this in previous assignments to record execution time\n","\n","    Parameters\n","    ----------\n","    func : FUNCTION\n","        Function we're recording and printing execution time of.\n","    \"\"\"\n","    \n","    @functools.wraps(func)\n","    def record_exec_time(*args, **kwargs):\n","        start_time = time.perf_counter()\n","        mn = func(*args, **kwargs)\n","        execution_time = time.perf_counter() - start_time\n","        print(\"Execution Time: \", execution_time)\n","        return mn\n","\n","    return record_exec_time\n","\n","\n","\n","def part_a_1_basic3():\n","    \"\"\"\n","    6 Convolutional & Pooling layers -> 1 Densely Connected layers -> SoftMax layer\n","\n","    Returns\n","    -------\n","    model : Model object\n","        Model described above.\n","\n","    \"\"\"\n","    \n","    input = keras.Input(shape=(64,64,3))\n","    conv1_op = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding=\"same\")(input)\n","    pool1_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1_op)\n","    conv2_op = keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding=\"same\")(pool1_op)\n","    pool2_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2_op)    \n","    conv3_op = keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding=\"same\")(pool2_op)\n","    pool3_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3_op)\n","    conv4_op = keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding=\"same\")(pool3_op)\n","    pool4_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4_op)\n","    conv5_op = keras.layers.Conv2D(86, kernel_size=3, activation='relu', padding=\"same\")(pool4_op)\n","    pool5_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv5_op)\n","    conv6_op = keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding=\"same\")(pool5_op)\n","    pool6_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv6_op)    \n","    flat_op = keras.layers.Flatten()(pool6_op)\n","    dense_op = keras.layers.Dense(512, activation='relu')(flat_op)\n","    smax_op = keras.layers.Dense(9, activation=tf.nn.softmax)(dense_op)\n","    model = keras.Model(inputs=input, outputs=smax_op)\n","    \n","    return model\n","\n","\n","\n","def part_a_1_basic5():\n","    \"\"\"\n","    Convolutional & 4 Pooling layers -> 1 Densely Connected layers -> SoftMax layer\n","\n","    Returns\n","    -------\n","    model : Model object\n","        Model described above.\n","\n","    \"\"\"\n","     \n","    input = keras.Input(shape=(64,64,3))\n","    conv1_op = keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding=\"same\")(input)\n","    pool1_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1_op)\n","    conv2_op = keras.layers.Conv2D(128, kernel_size=3, activation='relu', padding=\"same\")(pool1_op)\n","    pool2_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2_op)    \n","    conv3_op = keras.layers.Conv2D(64, kernel_size=3, activation='relu', padding=\"same\")(pool2_op)\n","    conv4_op = keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding=\"same\")(conv3_op)\n","    pool3_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4_op)\n","    conv5_op = keras.layers.Conv2D(16, kernel_size=3, activation='relu', padding=\"same\")(pool3_op)\n","    pool4_op = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv5_op)\n","    \n","    flat_op = keras.layers.Flatten()(pool4_op)\n","    dense_op = keras.layers.Dense(512, activation='relu')(flat_op)\n","    smax_op = keras.layers.Dense(9, activation=tf.nn.softmax)(dense_op)\n","    model = keras.Model(inputs=input, outputs=smax_op)\n","\n","    return model\n","    \n","\n","def part_a_1_data_augmentation(X, y):\n","    \"\"\"\n","    Take in training data and target class labels and return image generator object\n","\n","    Parameters\n","    ----------\n","    X : Numpy Array\n","        Training data.\n","    y : Numpy Array\n","        Training target classes.\n","        \n","    Returns\n","    -------\n","    train_generator : Training generator object\n","        Feed data augmentated images to NN.\n","\n","    \"\"\"\n","    \n","    train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.1,\n","                                                                     zoom_range=0.3,\n","                                                                     rotation_range=20,\n","                                                                     horizontal_flip=True, \n","                                                                     vertical_flip=True)\n","    \n","    train_generator = train_data_gen.flow(X, y, batch_size = 32)\n","    \n","    return train_generator\n","    \n","\n","\n","def save_model(model, model_name, X, y, X_val, y_val):\n","    \"\"\"\n","    Compile and fit model and save best weights over NUM_EPOCHS epochs\n","\n","    Parameters\n","    ----------\n","    model : Keras Model\n","        Model.\n","    model_name : String\n","        name to save model as.\n","    X : Numpy Array\n","        Training data.\n","    y : Numpy Array\n","        Training target classes.\n","    X_val : Numpy Array\n","        Test data.\n","    y_val : Numpy Array\n","        Test target classes.\n","\n","    Returns\n","    -------\n","    None.\n","\n","    \"\"\"\n","    \n","    image_gen = part_a_1_data_augmentation(X, y)\n","    NUM_EPOCHS= 20\n","    check_name = 'weights.hdf5'\n","    os.path.isfile(check_name)\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(check_name, monitor='val_loss',\n","                                                    mode='min', save_best_only=True, verbose=1)\n","    model.compile(optimizer='adam', \n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    history = model.fit(image_gen, epochs=NUM_EPOCHS,  validation_data=(X_val, y_val), callbacks=[checkpoint])\n","    model.load_weights(check_name)\n","    model.save(model_name)\n","    \n","\n","def create_models(model_names, X, y, X_val, y_val):\n","    \"\"\"\n","    Create 4 models based on 2 models from PartA_1\n","\n","    Parameters\n","    ----------\n","    model_names : List\n","        Names models will be saved as.\n","    X : Numpy Array\n","        Training data.\n","    y : Numpy Array\n","        Training target classes.\n","    X_val : Numpy Array\n","        Test data.\n","    y_val : Numpy Array\n","        Test target classes.\n","\n","    Returns\n","    -------\n","    None.\n","\n","    \"\"\"\n","    \n","    model3 = part_a_1_basic3()\n","    model5 = part_a_1_basic5()\n","    mname1, mname2, mname3, mname4 = model_names \n","    save_model(model3, mname1, X, y, X_val, y_val)\n","    save_model(model3, mname2, X, y, X_val, y_val)\n","    save_model(model5, mname3, X, y, X_val, y_val)\n","    save_model(model5, mname4, X, y, X_val, y_val)\n","    \n","        \n","    \n","\n","    \n","def ens_predict(models, X):\n","    \"\"\"\n","    Aggregate predictinos of all models and return result\n","\n","    Parameters\n","    ----------\n","    models : List\n","        All ensemble models.\n","    X : Numpy array\n","        Test data.\n","\n","    Returns\n","    -------\n","    result : Numpy array\n","        Predictions.\n","\n","    \"\"\"\n","    \n","    y_pred = [model.predict(X) for model in models]     #Retrieve predictinos for each model and store in y_pred\n","    y_pred = np.array(y_pred)                           #Convert to numpy array  \n","    avg = np.divide(np.sum(y_pred, axis = 0), 9)        #Find average\n","    result = np.argmax(avg, axis=1)                     #Return max value\n","    \n","    return result\n","\n","\n","@exec_time \n","def main():\n","    \"\"\"\n","    Ensemble model: Create 4 models (using 2 models from PartA_1)\n","    Aggregate results \n","\n","    Returns\n","    -------\n","    None.\n","\n","    \"\"\"\n","\n","    X, y, X_val, y_val = loadDataH5()\n","    models = []    \n","    model_names = ('m1', 'm2', 'm3', 'm4')\n","    mname1, mname2, mname3, mname4 = model_names   \n","    create_models(model_names, X, y, X_val, y_val)\n","   \n","    for m in model_names:\n","        model = load_model(m)\n","        results = model.evaluate(X_val, y_val, verbose=0)\n","        print(\"Loaded model: {}, Accuracy = {}\".format(m, results[1]))  \n","        models.append(model)\n","\n","    predictions = ens_predict(models, X_val)  \n","    print(accuracy_score(predictions, y_val))\n","\n","    \n","    \n","def loadDataH5():\n","    \"\"\"\n","    Extract dataset (supplied in assignment)    \n","    \n","    Returns\n","    -------\n","    trainX : NUMPY ARRAY\n","        Training data.\n","    trainY : NUMPY ARRAY\n","        Training target class values.\n","    valX : NUMPY ARRAY\n","        Test data.\n","    valY : NUMPY ARRAY\n","        Test target class values.\n","    \"\"\"\n","    \n","    with h5py.File('earth_data.h5','r') as hf:\n","        trainX = np.array(hf.get('trainX'))\n","        trainY = np.array(hf.get('trainY'))\n","        valX = np.array(hf.get('valX'))\n","        valY = np.array(hf.get('valY'))\n","        # print (trainX.shape,trainY.shape)\n","        # print (valX.shape,valY.shape)\n","    return trainX, trainY, valX, valY\n","\n","\n","if __name__==\"__main__\":\n","    main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","176/600 [=======>......................] - ETA: 22s - loss: 1.9608 - accuracy: 0.3116"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ecfb9e9fd687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# print(\"Local Devices: \\n\", device_lib.list_local_devices())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-ecfb9e9fd687>\u001b[0m in \u001b[0;36mrecord_exec_time\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecord_exec_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mexecution_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Execution Time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-ecfb9e9fd687>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmodel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'm1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mmname1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mcreate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-ecfb9e9fd687>\u001b[0m in \u001b[0;36mcreate_models\u001b[0;34m(model_names, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_a_1_basic5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmname1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmname3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-ecfb9e9fd687>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, model_name, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m    128\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}