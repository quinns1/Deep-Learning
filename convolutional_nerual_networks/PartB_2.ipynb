{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PartB_2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO00GIsIUYrsQjdPDhfoi0f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RZY7hDOPs_6p","executionInfo":{"status":"error","timestamp":1619970332873,"user_tz":-60,"elapsed":394199,"user":{"displayName":"Shane Quinn","photoUrl":"","userId":"04299873785165069898"}},"outputId":"127a9472-afb3-404c-e847-aa2c2c025c6f"},"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Name: Shane Quinn\n","Student Number: R00144107\n","Email: shane.quinn1@mycit.ie\n","Course: MSc Artificial Intelligence\n","Module: Deep Learning\n","Date: 01/05/2021\n","\"\"\"\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n","# !unzip \"/content/gdrive/My Drive/datasets/earth_data.zip\" -d \"./\"\n","\n","# !ls\n","\n","\n","import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","from tensorflow.python.client import device_lib\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras.models import load_model\n","from sklearn.metrics import accuracy_score\n","import functools\n","import time\n","import os\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.metrics import f1_score\n","\n","\n","def exec_time(func):\n","    \"\"\"\n","    Generic Execution time recorder, pass in function. Records execution time using decorators\n","    Have used this in previous assignments to record execution time\n","\n","    Parameters\n","    ----------\n","    func : FUNCTION\n","        Function we're recording and printing execution time of.\n","    \"\"\"\n","    \n","    @functools.wraps(func)\n","    def record_exec_time(*args, **kwargs):\n","        start_time = time.perf_counter()\n","        mn = func(*args, **kwargs)\n","        execution_time = time.perf_counter() - start_time\n","        print(\"Execution Time: \", execution_time)\n","        return mn\n","\n","    return record_exec_time\n","\n","\n","def part_a_1_data_augmentation(X, y):\n","    \"\"\"\n","    Take in training data and target class labels and return image generator object\n","\n","    Parameters\n","    ----------\n","    X : Numpy Array\n","        Training data.\n","    y : Numpy Array\n","        Training target classes.\n","        \n","    Returns\n","    -------\n","    train_generator : Training generator object\n","        Feed data augmentated images to NN.\n","\n","    \"\"\"\n","    \n","    train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.1,\n","                                                                     zoom_range=0.3,\n","                                                                     rotation_range=20,\n","                                                                     horizontal_flip=True, \n","                                                                     vertical_flip=True)\n","    \n","    train_generator = train_data_gen.flow(X, y, batch_size = 32)\n","    \n","    return train_generator\n","\n","\n","def plotAccLoss(H, NUM_EPOCHS):\n","    \"\"\"\n","    From Lecture notes\n","\n","    Parameters\n","    ----------\n","    H : TYPE\n","        DESCRIPTION.\n","    NUM_EPOCHS : TYPE\n","        DESCRIPTION.\n","\n","    Returns\n","    -------\n","    None.\n","\n","    \"\"\"\n","\n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n","    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n","    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n","    plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n","    plt.title(\"Training Loss and Accuracy: \")\n","    plt.xlabel(\"Epoch #\")\n","    plt.ylabel(\"Loss/Accuracy\")\n","    plt.legend()\n","    plt.show()\n","  \n","  \n","def fine_tune(X, y, X_val, y_val ):\n","    \"\"\"\n","    Create transfer learning model using VGG -> Flatten -> 254 Densely conencted -> SoftMax\n","    \n","    Train densely connected layer - checkpoint and save best weights. (VGG remains untrainable)\n","    \n","    Unfreeze some weights in VGG and train with a lower learning rate\n","    \n","\n","    Parameters\n","    ----------\n","    X : Numpy Array\n","        Training data.\n","    y : Numpy Array\n","        Training target classes.\n","    X_val : Numpy Array\n","        Test data.\n","    y_val : Numpy Array\n","        Test target classes.\n","\n","    Returns\n","    -------\n","    model : TYPE\n","        DESCRIPTION.\n","\n","    \"\"\"\n","\n","    NUM_EPOCHS = 20\n","    vggModel = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n","    check_name = 'weights.hdf5'\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint(check_name, monitor='val_loss',\n","                                                    mode='min', save_best_only=True, verbose=1)\n","    vggModel.trainable = False\n","    model = tf.keras.models.Sequential()\n","    model.add(vggModel)\n","    model.add(tf.keras.layers.Flatten())\n","    model.add(tf.keras.layers.Dense(254, activation='relu'))\n","    model.add(tf.keras.layers.Dense(9, activation='sigmoid'))  \n","    print(model.summary())  \n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","    \n","    image_gen = part_a_1_data_augmentation(X, y)\n","    history = model.fit(image_gen, epochs=NUM_EPOCHS,  validation_data=(X_val, y_val), callbacks=[checkpoint])\n","    plotAccLoss(history, NUM_EPOCHS) \n","    model.load_weights(check_name)\n","    \n","    #Layers to become trainable\n","    layers_trainable = ['block3_conv1', 'block3_conv2', 'block3_conv3', 'block4_conv1', 'block4_conv2', 'block4_conv3, block5_conv1', 'block5_conv2', 'block5_conv3']\n","    vggModel.trainable = True\n","\n","    for layer in vggModel.layers:\n","        layer.trainable = False\n","        if layer.name in layers_trainable:\n","            trainableFlag = True\n","            layer.trainable = True\n","\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","    history = model.fit(image_gen, epochs=NUM_EPOCHS,  validation_data=(X_val, y_val), callbacks=[checkpoint])\n","    model.load_weights(check_name)\n","    plotAccLoss(history, NUM_EPOCHS)\n","    \n","    return model \n","\n","\n","\n","@exec_time  \n","def main():\n","    \"\"\"\n","    Fine tune model defined in fine_tune() method, save model\n","    Can load saved model in and evaluate performance\n","\n","    Returns\n","    -------\n","    None.\n","\n","    \"\"\"\n","\n","    X, y, X_val, y_val = loadDataH5()\n","    model_name = 'VGG_Dense_NN.h5'\n","    \n","    \n","    model = fine_tune(X, y, X_val, y_val)\n","    model.save(model_name)\n","    \n","    'Uncomment below to load and test model previously saved'\n","    # model = load_model(model_name)\n","    # results = model.evaluate(X_val, y_val, batch_size=32)\n","    # print(results)\n","\n","\n","\n","    \n","    \n","    \n","def loadDataH5():\n","    \"\"\"\n","    Extract dataset (supplied in assignment)    \n","    \n","    Returns\n","    -------\n","    trainX : NUMPY ARRAY\n","        Training data.\n","    trainY : NUMPY ARRAY\n","        Training target class values.\n","    valX : NUMPY ARRAY\n","        Test data.\n","    valY : NUMPY ARRAY\n","        Test target class values.\n","    \"\"\"   \n","    \n","    with h5py.File('earth_data.h5','r') as hf:\n","        trainX = np.array(hf.get('trainX'))\n","        trainY = np.array(hf.get('trainY'))\n","        valX = np.array(hf.get('valX'))\n","        valY = np.array(hf.get('valY'))\n","        # print (trainX.shape,trainY.shape)\n","        # print (valX.shape,valY.shape)\n","    return trainX, trainY, valX, valY\n","\n","\n","if __name__==\"__main__\":\n","    main() "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","Archive:  /content/gdrive/My Drive/datasets/earth_data.zip\n","  inflating: ./earth_data.h5         \n","earth_data.h5  gdrive  sample_data\n","Local Devices: \n"," [name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 16701630876767657105\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14674281152\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 14555843857171873624\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 254)               520446    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 9)                 2295      \n","=================================================================\n","Total params: 15,237,429\n","Trainable params: 522,741\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","600/600 [==============================] - 58s 42ms/step - loss: 2.5487 - accuracy: 0.7192 - val_loss: 0.6639 - val_accuracy: 0.7987\n","\n","Epoch 00001: val_loss improved from inf to 0.66390, saving model to weights.hdf5\n","Epoch 2/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.5607 - accuracy: 0.8154 - val_loss: 0.4352 - val_accuracy: 0.8658\n","\n","Epoch 00002: val_loss improved from 0.66390 to 0.43520, saving model to weights.hdf5\n","Epoch 3/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.4541 - accuracy: 0.8502 - val_loss: 0.3779 - val_accuracy: 0.8806\n","\n","Epoch 00003: val_loss improved from 0.43520 to 0.37786, saving model to weights.hdf5\n","Epoch 4/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.3993 - accuracy: 0.8656 - val_loss: 0.5165 - val_accuracy: 0.8617\n","\n","Epoch 00004: val_loss did not improve from 0.37786\n","Epoch 5/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.4005 - accuracy: 0.8639 - val_loss: 0.3601 - val_accuracy: 0.8888\n","\n","Epoch 00005: val_loss improved from 0.37786 to 0.36006, saving model to weights.hdf5\n","Epoch 6/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.3780 - accuracy: 0.8748 - val_loss: 0.3678 - val_accuracy: 0.8819\n","\n","Epoch 00006: val_loss did not improve from 0.36006\n","Epoch 7/20\n","600/600 [==============================] - 25s 42ms/step - loss: 0.3680 - accuracy: 0.8796 - val_loss: 0.3917 - val_accuracy: 0.8798\n","\n","Epoch 00007: val_loss did not improve from 0.36006\n","Epoch 8/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.3503 - accuracy: 0.8838 - val_loss: 0.3523 - val_accuracy: 0.8871\n","\n","Epoch 00008: val_loss improved from 0.36006 to 0.35232, saving model to weights.hdf5\n","Epoch 9/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.3588 - accuracy: 0.8794 - val_loss: 0.3775 - val_accuracy: 0.8831\n","\n","Epoch 00009: val_loss did not improve from 0.35232\n","Epoch 10/20\n","600/600 [==============================] - 25s 41ms/step - loss: 0.3605 - accuracy: 0.8787 - val_loss: 0.3381 - val_accuracy: 0.8921\n","\n","Epoch 00010: val_loss improved from 0.35232 to 0.33806, saving model to weights.hdf5\n","Epoch 11/20\n","600/600 [==============================] - 25s 42ms/step - loss: 0.3313 - accuracy: 0.8905 - val_loss: 0.3662 - val_accuracy: 0.8904\n","\n","Epoch 00011: val_loss did not improve from 0.33806\n","Epoch 12/20\n","591/600 [============================>.] - ETA: 0s - loss: 0.3449 - accuracy: 0.8848"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4db2c6cf74d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Local Devices: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-4db2c6cf74d1>\u001b[0m in \u001b[0;36mrecord_exec_time\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecord_exec_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mexecution_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Execution Time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4db2c6cf74d1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;34m'Uncomment below to load and test model previously saved'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4db2c6cf74d1>\u001b[0m in \u001b[0;36mfine_tune\u001b[0;34m(X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mimage_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_a_1_data_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mplotAccLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}